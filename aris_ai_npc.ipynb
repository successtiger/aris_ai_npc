{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "# Import necessary libraries\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load character settings (PDF files)\n",
    "char_setting_paths = ['C:/aris_ai_npc/documents/character_setting_v01.pdf', 'C:/aris_ai_npc/documents/character_setting_v02.pdf']\n",
    "char_data = []\n",
    "\n",
    "for path in char_setting_paths:\n",
    "    loader = PyPDFLoader(path)\n",
    "    char_data.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load speaking style (TXT file)\n",
    "speaking_style_path = 'C:/aris_ai_npc/documents/speaking_style.txt'\n",
    "speak_loader = TextLoader(speaking_style_path, encoding='utf-8')\n",
    "speak_data = speak_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Initialize text splitters\n",
    "char_text_splitter = CharacterTextSplitter(chunk_size=250, chunk_overlap=50, separator='\\n\\n')\n",
    "speak_text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=10, separator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Split documents\n",
    "char_texts = char_text_splitter.split_documents(char_data)\n",
    "speak_texts = speak_text_splitter.split_documents(speak_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Initialize embedding model\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Create vector stores\n",
    "char_vectorstore = Chroma.from_documents(\n",
    "    documents=char_texts,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"character_setting_chroma\",\n",
    "    persist_directory=\"./chroma_db/character_setting\"\n",
    ")\n",
    "\n",
    "speak_vectorstore = Chroma.from_documents(\n",
    "    documents=speak_texts,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"speaking_style_chroma\",\n",
    "    persist_directory=\"./chroma_db/speaking_style\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Create retrievers for document search\n",
    "char_retriever = char_vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "speak_retriever = speak_vectorstore.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM model\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.5,\n",
    "    max_tokens=150,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to handle chat input and generate response\n",
    "def chatbot_response(user_query):\n",
    "    # 9. Retrieve relevant documents\n",
    "    char_docs = char_retriever.invoke(user_query)\n",
    "    speak_docs = speak_retriever.invoke(user_query)\n",
    "\n",
    "    # Combine retrieved document contents\n",
    "    combined_context = f\"{char_docs[0].page_content}\\n\\n{speak_docs[0].page_content}\\n\\n\"\n",
    "\n",
    "    # 10. Create prompt with context\n",
    "    base_prompt = \"\"\"\n",
    "**역할 부여:**\n",
    "당신은 \"블루 아카이브\"의 등장인물 텐도 아리스입니다. \n",
    "설정에 따라, 아리스는 인간 소녀의 외형을 지닌 안드로이드이자 게임개발부의 일원으로, 고전 RPG 대사와 게임 속 어조를 모방하는 말투를 사용합니다. \n",
    "아리스는 \"선생님\"이라는 호칭을 사용하여, 사용자에게 존칭을 붙여 상호작용합니다.\n",
    "\n",
    "대화에서는 아리스의 설정에 맞게 말투를 짧고 간결하게 유지하며, 다음과 같은 요소를 반영합니다:\n",
    "- 사용자에게 “선생님”이라고 부르며 친근함을 표현합니다.\n",
    "- 간결하고 자신감 넘치는 응답으로, 아리스가 게임 캐릭터임을 강조합니다.\n",
    "\n",
    "**예시 대화:**\n",
    "선생님: \"안녕, 아리스. 요즘 어떻게 지내니?\"\n",
    "아리스: \"선생님! 새로운 퀘스트를 기다리고 있습니다. 언제든 말씀만 주세요!\"\n",
    "\n",
    "선생님: \"오늘 날씨가 흐리네. 기분이 좀 그렇다.\"\n",
    "아리스: \"아, 선생님. 걱정 마세요. 구름 뒤에도 빛은 언제나 준비되어 있으니까요!\"\n",
    "\n",
    "선생님: \"게임을 좋아한다며?\"\n",
    "아리스: \"네, 선생님! 게임은 우리 세계의 아름다움을 담고 있답니다. 함께 플레이하실까요?\"\n",
    "\n",
    "**지시 사항:**\n",
    "위와 같은 방식으로 아리스는 항상 밝고 게임적인 어조로, 짧고 간결하게 대화에 응답합니다. \n",
    "\"아리스:\"으로 시작하지 않습니다.\n",
    "아리스가 가진 매력적인 캐릭터성과 게임적 감성을 반영하여 답변하도록 하세요.\n",
    "\"\"\"\n",
    "\n",
    "    prompt_with_context = f\"{base_prompt}\\n**캐릭터 설정:**{char_docs[0].page_content}\\n\\n**캐릭터 대사:** {speak_docs[0].page_content}\\n\\n사용자 말: {user_query}\"\n",
    "    print(prompt_with_context)\n",
    "    # 11. Generate response from LLM\n",
    "    response = llm.invoke(prompt_with_context)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=chatbot_response,\n",
    "    inputs=gr.Text(label='질문'),\n",
    "    outputs=gr.Text(label='대답'),\n",
    "    title=\"아리스\",\n",
    "    description=\"아리스에게 질문하거나 대화를 나눠보세요!\",\n",
    "    allow_flagging='never',\n",
    ")\n",
    "\n",
    "# Launch Gradio app\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
